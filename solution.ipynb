{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28bcd0b4",
   "metadata": {},
   "source": [
    "## Этап 1. Сбор и подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98717df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pavelstepanov/dl_projects/text-autocomplete/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.baseline_comparison import DistilGPT2Baseline\n",
    "from src.model_evaluation import compare_models, generate_examples\n",
    "from src.configs import CONFIG, DATA_PATH, PROJECT_PATH, TOKENIZER\n",
    "from src.next_token_dataset import NextTokenDataset, collate_fn\n",
    "from src.lstm_model import LSTMModel\n",
    "from src.lstm_train import train_model\n",
    "from src.data_utils import load_tweets, process_tweets_dataset, split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2cdf65a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cpu'), '2.7.1')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device, torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "465bc58d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x136f9c970>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a4658a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-10-11 00:37:58--  https://code.s3.yandex.net/deep-learning/tweets.txt\n",
      "Resolving code.s3.yandex.net (code.s3.yandex.net)... 93.158.134.158\n",
      "Connecting to code.s3.yandex.net (code.s3.yandex.net)|93.158.134.158|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 120323600 (115M) [text/plain]\n",
      "Saving to: ‘data/tweets.txt’\n",
      "\n",
      "tweets.txt          100%[===================>] 114,75M  36,8MB/s    in 3,1s    \n",
      "\n",
      "2025-10-11 00:38:02 (36,8 MB/s) - ‘data/tweets.txt’ saved [120323600/120323600]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -P data/ https://code.s3.yandex.net/deep-learning/tweets.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b7dd51",
   "metadata": {},
   "source": [
    "### Загружаем и обрабатываем твиты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e8e5cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обработка твитов:   0%|          | 5989/1600498 [00:12<56:46, 468.06it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m processed_texts \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_tweets_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTOKENIZER\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dl_projects/text-autocomplete/src/data_utils.py:63\u001b[0m, in \u001b[0;36mprocess_tweets_dataset\u001b[0;34m(tweets_path, processed_path, tokenizer)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m json\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[1;32m     62\u001b[0m tweets \u001b[38;5;241m=\u001b[39m load_tweets(tweets_path)\n\u001b[0;32m---> 63\u001b[0m processed_texts \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_tweets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtweets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m save_processed_data(processed_texts, processed_path)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m processed_texts\n",
      "File \u001b[0;32m~/dl_projects/text-autocomplete/src/data_utils.py:41\u001b[0m, in \u001b[0;36mprocess_tweets\u001b[0;34m(tweets, tokenizer)\u001b[0m\n\u001b[1;32m     39\u001b[0m processed_texts \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tweet \u001b[38;5;129;01min\u001b[39;00m tqdm(tweets, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mОбработка твитов\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 41\u001b[0m     processed_text \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtweet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     processed_texts\u001b[38;5;241m.\u001b[39mappend(processed_text)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m processed_texts\n",
      "File \u001b[0;32m~/dl_projects/text-autocomplete/src/data_utils.py:27\u001b[0m, in \u001b[0;36mpreprocess_text\u001b[0;34m(text, tokenizer)\u001b[0m\n\u001b[1;32m     24\u001b[0m text \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms+\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m, text)\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     25\u001b[0m text \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[^a-z0-9\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m!\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m<\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m_]\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, text)\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokenizer:\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mtokenize(text)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m text\n",
      "File \u001b[0;32m~/dl_projects/text-autocomplete/.venv/lib/python3.12/site-packages/transformers/tokenization_utils_fast.py:279\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast.__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m    276\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m    Size of the full vocabulary with the added tokens.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 279\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_vocab_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwith_added_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "processed_texts = process_tweets_dataset(tokenizer=TOKENIZER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6648560b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'processed_texts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mprocessed_texts\u001b[49m[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'processed_texts' is not defined"
     ]
    }
   ],
   "source": [
    "print(processed_texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a955af",
   "metadata": {},
   "source": [
    "### Разбиваем датасет на трейн, валидацию и тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82ec8869",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, val_texts, test_texts = split_data(processed_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9661fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NextTokenDataset(train_texts, TOKENIZER)\n",
    "val_dataset   = NextTokenDataset(val_texts, TOKENIZER)\n",
    "test_dataset  = NextTokenDataset(test_texts, TOKENIZER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17d86be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_token_id = TOKENIZER.pad_token_id or 0\n",
    "batch_size = CONFIG['training']['batch_size']\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=lambda b: collate_fn(b, pad_token_id))\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=lambda b: collate_fn(b, pad_token_id))\n",
    "    \n",
    "test_loader  = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=lambda b: collate_fn(b, pad_token_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4030f419",
   "metadata": {},
   "source": [
    "## Этап 2. Объявление модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a753a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMModel(\n",
    "    vocab_size = TOKENIZER.vocab_size,\n",
    "    embed_dim=CONFIG['model']['embed_dim'],\n",
    "    hidden_dim=CONFIG['model']['hidden_dim'],\n",
    "    num_layers=CONFIG['model']['num_layers'],\n",
    "    pad_token_id=pad_token_id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b1d633",
   "metadata": {},
   "source": [
    "## Этап 3. Тренировка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469dc2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 126/126 [00:48<00:00,  2.60it/s]\n",
      "Epoch 2/10: 100%|██████████| 126/126 [00:47<00:00,  2.65it/s]\n",
      "Epoch 3/10: 100%|██████████| 126/126 [00:46<00:00,  2.70it/s]\n",
      "Epoch 4/10:  16%|█▌        | 20/126 [00:08<00:43,  2.46it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trained_model, best_path \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTOKENIZER\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtraining\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtraining\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtraining\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dl_projects/text-autocomplete/src/lstm_train.py:54\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, tokenizer, device, epochs, lr, weight_decay, pad_token_id, save_dir)\u001b[0m\n\u001b[1;32m     51\u001b[0m logits, _ \u001b[38;5;241m=\u001b[39m model(input_ids)\n\u001b[1;32m     53\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(logits\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, logits\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)), labels\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m---> 54\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m     56\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/dl_projects/text-autocomplete/.venv/lib/python3.12/site-packages/torch/_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    647\u001b[0m     )\n\u001b[0;32m--> 648\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dl_projects/text-autocomplete/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dl_projects/text-autocomplete/.venv/lib/python3.12/site-packages/torch/autograd/graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trained_model = train_model(\n",
    "    model, \n",
    "    train_loader, \n",
    "    val_loader, \n",
    "    TOKENIZER, \n",
    "    device,\n",
    "    epochs=CONFIG['training']['epochs'],\n",
    "    lr=CONFIG['training']['lr'],\n",
    "    weight_decay=CONFIG['training']['weight_decay'],\n",
    "    pad_token_id=pad_token_id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9072a75e",
   "metadata": {},
   "source": [
    "## Этап 4. Использование предобученного трансформера"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5976924b",
   "metadata": {},
   "source": [
    "Загрузка baseline модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b23512d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка предобученной модели distilgpt2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель загружена успешно!\n"
     ]
    }
   ],
   "source": [
    "baseline = DistilGPT2Baseline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92c73a6",
   "metadata": {},
   "source": [
    "Создаем валидационную выборку из исходных текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a050fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_original, val_original, test_original = split_data(load_tweets(), save_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a417bc5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluate_scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mevaluate_scores\u001b[49m(baseline, val_original)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'evaluate_scores' is not defined"
     ]
    }
   ],
   "source": [
    "evaluate_scores(baseline, val_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5635cbcf",
   "metadata": {},
   "source": [
    "## Этап 5. Формулирование выводов\n",
    "\n",
    "Сравниваем производительность двух моделей на валидационной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae1723c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Сравнение LSTM с baseline моделью ===\n",
      "Оценка LSTM модели...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оценка baseline модели...\n",
      "Оценка distilgpt2 на 2000 примерах...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:13<00:00, 14.98it/s]\n",
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обработано 1974 примеров\n",
      "\n",
      "Сравнение результатов:\n",
      "Модель          ROUGE-1    ROUGE-2    ROUGE-L   \n",
      "--------------------------------------------------\n",
      "LSTM            0.0334     0.0028     0.0327\n",
      "Baseline        0.0658     0.0084     0.0651\n",
      "\n",
      "Baseline показывает лучшие результаты (ROUGE-L: 0.0651 vs 0.0327)\n"
     ]
    }
   ],
   "source": [
    "results = compare_models(model, baseline, val_loader, val_original, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2351cc3",
   "metadata": {},
   "source": [
    "Извлекаем результаты для графиков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37f1d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_rouge1 = results['lstm_rouge1']\n",
    "lstm_rouge2 = results['lstm_rouge2']\n",
    "lstm_rouge_l = results['lstm_rouge_l']\n",
    "final_rouge1 = results['baseline_rouge1']\n",
    "final_rouge2 = results['baseline_rouge2']\n",
    "final_rouge_l = results['baseline_rouge_l']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2fcb43",
   "metadata": {},
   "source": [
    "График сравнения ROUGE метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ea7737f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lstm_rouge1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m fig, axes \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m      3\u001b[0m models \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLSTM\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistilgpt2\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 4\u001b[0m rouge1_scores \u001b[38;5;241m=\u001b[39m [\u001b[43mlstm_rouge1\u001b[49m, final_rouge1]\n\u001b[1;32m      5\u001b[0m rouge2_scores \u001b[38;5;241m=\u001b[39m [lstm_rouge2, final_rouge2]\n\u001b[1;32m      6\u001b[0m rougeL_scores \u001b[38;5;241m=\u001b[39m [lstm_rouge_l, final_rouge_l]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lstm_rouge1' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABMkAAAGyCAYAAAD+jZMxAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAIu1JREFUeJzt3X+sV3X9B/AXPwR0dVEjQQmjLLNSoUAIzTUbxabT/KNF2oSYP7LMFawS/AGZJeZXHVtiTNPsj0yqaWvBMKNYM2ksyM1KbEYFtUCoBMMChfPdOe0ih8+95udyP3Dv5/V4bEc4555zPx/eu/c83fOcz3kPKIqiCAAAAABIbODhfgMAAAAAcLgpyQAAAABIT0kGAAAAQHpKMgAAAADSU5IBAAAAkJ6SDAAAAID0lGQAAAAApKckAwAAACA9JRkAAAAA6SnJAAAAAEiv6ZLs5z//eZx//vlxwgknxIABA+IHP/jB/zxm1apV8e53vzuGDh0ab3nLW+L+++/v6fsFoM3JGQBaSc4A0Gsl2c6dO2PcuHGxePHiV7X/H//4xzjvvPPinHPOiSeeeCI++9nPxmWXXRaPPPJIsy8NQAJyBoBWkjMAdGdAURRF9FB55eXhhx+OCy+8sNt9rrnmmli2bFn85je/2bftox/9aDz33HOxYsWKnr40AAnIGQBaSc4AsL/B0WKrV6+OqVOn1rZNmzatugLTnV27dlVLp71798Y//vGPeN3rXlcFGQAHp7w+8vzzz1cfNRk4sH8/nlLOAPQ9ckbOAPTHnGl5SbZ58+YYOXJkbVu5vmPHjvj3v/8dRx55ZMMxCxcujBtvvLHVbw0gvU2bNsUb3vCG6M/kDEDfJWcA6E850/KSrCfmzZsXc+bM2be+ffv2OPHEE6t/fEdHx2F9bwDtoPwf+zFjxsRrX/vayEjOALSWnJEzAP0xZ1peko0aNSq2bNlS21aul+HQ1VWXUjlrTLkcqDxGqAD0nnb4yIecAei75EydnAHo2znT8gcETJkyJVauXFnb9uijj1bbAeBgyRkAWknOAOTRdEn2r3/9q5r6uFw6p0Qu/75x48Z9txbPmDFj3/5XXnllbNiwIb7whS/E+vXr46677orvfve7MXv27N78dwDQJuQMAK0kZwDotZLsV7/6VbzrXe+qllL5Wfvy7/Pnz6/W//a3v+0LmNKb3vSmasrk8mrLuHHj4vbbb49vfOMb1YwwAHAgOQNAK8kZALozoCjnzewHD2QbPnx49cBLn+EHOHjOq3XGA6B3Oa/WGQ+A/nFebfkzyQAAAACgr1OSAQAAAJCekgwAAACA9JRkAAAAAKSnJAMAAAAgPSUZAAAAAOkpyQAAAABIT0kGAAAAQHpKMgAAAADSU5IBAAAAkJ6SDAAAAID0lGQAAAAApKckAwAAACA9JRkAAAAA6SnJAAAAAEhPSQYAAABAekoyAAAAANJTkgEAAACQnpIMAAAAgPSUZAAAAACkpyQDAAAAID0lGQAAAADpKckAAAAASE9JBgAAAEB6SjIAAAAA0lOSAQAAAJCekgwAAACA9JRkAAAAAKSnJAMAAAAgPSUZAAAAAOkpyQAAAABIT0kGAAAAQHpKMgAAAADSU5IBAAAAkJ6SDAAAAID0lGQAAAAApKckAwAAACA9JRkAAAAA6SnJAAAAAEhPSQYAAABAekoyAAAAANJTkgEAAACQnpIMAAAAgPSUZAAAAACkpyQDAAAAID0lGQAAAADpKckAAAAASE9JBgAAAEB6SjIAAAAA0lOSAQAAAJCekgwAAACA9JRkAAAAAKSnJAMAAAAgPSUZAAAAAOkpyQAAAABIT0kGAAAAQHpKMgAAAADSU5IBAAAAkJ6SDAAAAID0lGQAAAAApKckAwAAACA9JRkAAAAA6SnJAAAAAEhPSQYAAABAekoyAAAAANJTkgEAAACQXo9KssWLF8fYsWNj2LBhMXny5FizZs0r7r9o0aJ429veFkceeWSMGTMmZs+eHf/5z396+p4BaHNyBoBWkjMA9EpJtnTp0pgzZ04sWLAg1q1bF+PGjYtp06bFs88+2+X+DzzwQMydO7fa/6mnnop77723+h7XXnttsy8NQAJyBoBWkjMA9FpJdscdd8Tll18es2bNine84x2xZMmSOOqoo+K+++7rcv/HH388zjrrrLj44ourqzUf/OAH46KLLvqfV2sAyEnOANBKcgaAXinJdu/eHWvXro2pU6e+/A0GDqzWV69e3eUxZ555ZnVMZ4hs2LAhli9fHueee263r7Nr167YsWNHbQGg/ckZAFpJzgDwSgZHE7Zt2xZ79uyJkSNH1raX6+vXr+/ymPKKS3nce9/73iiKIl566aW48sorX/H25IULF8aNN97YzFsDoA3IGQBaSc4AcFhnt1y1alXcfPPNcdddd1Wf+X/ooYdi2bJlcdNNN3V7zLx582L79u37lk2bNrX6bQLQT8kZAFpJzgDk0dSdZCNGjIhBgwbFli1batvL9VGjRnV5zA033BCXXHJJXHbZZdX6aaedFjt37owrrrgirrvuuur25gMNHTq0WgDIRc4A0EpyBoBeu5NsyJAhMWHChFi5cuW+bXv37q3Wp0yZ0uUxL7zwQkNwlMFUKm9XBoBOcgaAVpIzAPTanWSlcrrkmTNnxsSJE2PSpEmxaNGi6kpKOTtMacaMGTF69Ojqc/il888/v5pB5l3veldMnjw5nnnmmepqTLm9M1wAoJOcAaCV5AwAvVaSTZ8+PbZu3Rrz58+PzZs3x/jx42PFihX7Hn65cePG2pWW66+/PgYMGFD9+de//jVe//rXV4Hyla98pdmXBiABOQNAK8kZALozoOgH9wiXUyYPHz68euhlR0fH4X47AP2e82qd8QDoXc6rdcYDoH+cV1s+uyUAAAAA9HVKMgAAAADSU5IBAAAAkJ6SDAAAAID0lGQAAAAApKckAwAAACA9JRkAAAAA6SnJAAAAAEhPSQYAAABAekoyAAAAANJTkgEAAACQnpIMAAAAgPSUZAAAAACkpyQDAAAAID0lGQAAAADpKckAAAAASE9JBgAAAEB6SjIAAAAA0lOSAQAAAJCekgwAAACA9JRkAAAAAKSnJAMAAAAgPSUZAAAAAOkpyQAAAABIT0kGAAAAQHpKMgAAAADSU5IBAAAAkJ6SDAAAAID0lGQAAAAApKckAwAAACA9JRkAAAAA6SnJAAAAAEhPSQYAAABAekoyAAAAANJTkgEAAACQnpIMAAAAgPSUZAAAAACkpyQDAAAAID0lGQAAAADpKckAAAAASE9JBgAAAEB6SjIAAAAA0lOSAQAAAJCekgwAAACA9JRkAAAAAKSnJAMAAAAgPSUZAAAAAOkpyQAAAABIT0kGAAAAQHpKMgAAAADSU5IBAAAAkJ6SDAAAAID0lGQAAAAApKckAwAAACA9JRkAAAAA6SnJAAAAAEhPSQYAAABAekoyAAAAANJTkgEAAACQnpIMAAAAgPSUZAAAAACkpyQDAAAAID0lGQAAAADpKckAAAAASE9JBgAAAEB6SjIAAAAA0utRSbZ48eIYO3ZsDBs2LCZPnhxr1qx5xf2fe+65uOqqq+L444+PoUOHxsknnxzLly/v6XsGoM3JGQBaSc4A0JXB0aSlS5fGnDlzYsmSJVWgLFq0KKZNmxZPP/10HHfccQ377969Oz7wgQ9UX/v+978fo0ePjj//+c9x9NFHN/vSACQgZwBoJTkDQHcGFEVRRBPKIDnjjDPizjvvrNb37t0bY8aMiauvvjrmzp3bsH8ZPv/3f/8X69evjyOOOCJ6YseOHTF8+PDYvn17dHR09Oh7ANA/zqtyBqD/68vnVTkD0P/taNF5tamPW5ZXUdauXRtTp059+RsMHFitr169ustjfvjDH8aUKVOq25NHjhwZp556atx8882xZ8+ebl9n165d1T94/wWA9idnAGglOQNAr5Vk27Ztq8KgDIf9leubN2/u8pgNGzZUtyWXx5Wf27/hhhvi9ttvjy9/+cvdvs7ChQurRrBzKa/sAND+5AwArSRnADiss1uWty+Xn9+/++67Y8KECTF9+vS47rrrqtuWuzNv3rzqlrnOZdOmTa1+mwD0U3IGgFaSMwB5NPXg/hEjRsSgQYNiy5Ytte3l+qhRo7o8ppwBpvzsfnlcp7e//e3VlZryduchQ4Y0HFPOGFMuAOQiZwBoJTkDQK/dSVYGQHn1ZOXKlbUrK+V6+Tn9rpx11lnxzDPPVPt1+v3vf1+FTVeBAkBecgaAVpIzAPTqxy3L6ZLvueee+Na3vhVPPfVUfPKTn4ydO3fGrFmzqq/PmDGjur24U/n1f/zjH/GZz3ymCpNly5ZVD7osH3wJAAeSMwC0kpwBoFc+blkqP4O/devWmD9/fnWL8fjx42PFihX7Hn65cePGaoaYTuVDKh955JGYPXt2nH766TF69OgqYK655ppmXxqABOQMAK0kZwDozoCiKIro48opk8tZYcqHXnZ0dBzutwPQ7zmv1hkPgN7lvFpnPAD6x3m15bNbAgAAAEBfpyQDAAAAID0lGQAAAADpKckAAAAASE9JBgAAAEB6SjIAAAAA0lOSAQAAAJCekgwAAACA9JRkAAAAAKSnJAMAAAAgPSUZAAAAAOkpyQAAAABIT0kGAAAAQHpKMgAAAADSU5IBAAAAkJ6SDAAAAID0lGQAAAAApKckAwAAACA9JRkAAAAA6SnJAAAAAEhPSQYAAABAekoyAAAAANJTkgEAAACQnpIMAAAAgPSUZAAAAACkpyQDAAAAID0lGQAAAADpKckAAAAASE9JBgAAAEB6SjIAAAAA0lOSAQAAAJCekgwAAACA9JRkAAAAAKSnJAMAAAAgPSUZAAAAAOkpyQAAAABIT0kGAAAAQHpKMgAAAADSU5IBAAAAkJ6SDAAAAID0lGQAAAAApKckAwAAACA9JRkAAAAA6SnJAAAAAEhPSQYAAABAekoyAAAAANJTkgEAAACQnpIMAAAAgPSUZAAAAACkpyQDAAAAID0lGQAAAADpKckAAAAASE9JBgAAAEB6SjIAAAAA0lOSAQAAAJCekgwAAACA9JRkAAAAAKSnJAMAAAAgPSUZAAAAAOkpyQAAAABIT0kGAAAAQHpKMgAAAADSU5IBAAAAkJ6SDAAAAID0lGQAAAAApKckAwAAACC9HpVkixcvjrFjx8awYcNi8uTJsWbNmld13IMPPhgDBgyICy+8sCcvC0AScgaAVpM1ABx0SbZ06dKYM2dOLFiwINatWxfjxo2LadOmxbPPPvuKx/3pT3+Kz33uc3H22Wc3+5IAJCJnAGg1WQNAr5Rkd9xxR1x++eUxa9aseMc73hFLliyJo446Ku67775uj9mzZ0987GMfixtvvDHe/OY3N/uSACQiZwBoNVkDwEGXZLt37461a9fG1KlTX/4GAwdW66tXr+72uC996Utx3HHHxaWXXvqqXmfXrl2xY8eO2gJA+5MzALRD1sgZgAQl2bZt26orKCNHjqxtL9c3b97c5TGPPfZY3HvvvXHPPfe86tdZuHBhDB8+fN8yZsyYZt4mAP2UnAGgHbJGzgD0Ty2d3fL555+PSy65pAqTESNGvOrj5s2bF9u3b9+3bNq0qZVvE4B+Ss4A0BezRs4A9E+Dm9m5DIVBgwbFli1batvL9VGjRjXs/4c//KF6uOX555+/b9vevXv/+8KDB8fTTz8dJ510UsNxQ4cOrRYAcpEzALRD1sgZgAR3kg0ZMiQmTJgQK1eurAVEuT5lypSG/U855ZR48skn44knnti3XHDBBXHOOedUf3fbMQD7kzMAtJqsAaBX7iQrlVMlz5w5MyZOnBiTJk2KRYsWxc6dO6uZYUozZsyI0aNHV5/DHzZsWJx66qm1448++ujqzwO3A0BJzgDQarIGgF4pyaZPnx5bt26N+fPnVw+2HD9+fKxYsWLfgy83btxYzQ4DAD0hZwBoNVkDQFcGFEVRRB9XTplczgpTPvSyo6PjcL8dgH7PebXOeAD0LufVOuMB0D/Oqy6PAAAAAJCekgwAAACA9JRkAAAAAKSnJAMAAAAgPSUZAAAAAOkpyQAAAABIT0kGAAAAQHpKMgAAAADSU5IBAAAAkJ6SDAAAAID0lGQAAAAApKckAwAAACA9JRkAAAAA6SnJAAAAAEhPSQYAAABAekoyAAAAANJTkgEAAACQnpIMAAAAgPSUZAAAAACkpyQDAAAAID0lGQAAAADpKckAAAAASE9JBgAAAEB6SjIAAAAA0lOSAQAAAJCekgwAAACA9JRkAAAAAKSnJAMAAAAgPSUZAAAAAOkpyQAAAABIT0kGAAAAQHpKMgAAAADSU5IBAAAAkJ6SDAAAAID0lGQAAAAApKckAwAAACA9JRkAAAAA6SnJAAAAAEhPSQYAAABAekoyAAAAANJTkgEAAACQnpIMAAAAgPSUZAAAAACkpyQDAAAAID0lGQAAAADpKckAAAAASE9JBgAAAEB6SjIAAAAA0lOSAQAAAJCekgwAAACA9JRkAAAAAKSnJAMAAAAgPSUZAAAAAOkpyQAAAABIT0kGAAAAQHpKMgAAAADSU5IBAAAAkJ6SDAAAAID0lGQAAAAApKckAwAAACA9JRkAAAAA6SnJAAAAAEhPSQYAAABAekoyAAAAANJTkgEAAACQnpIMAAAAgPR6VJItXrw4xo4dG8OGDYvJkyfHmjVrut33nnvuibPPPjuOOeaYapk6deor7g8AcgaAVpM1ABx0SbZ06dKYM2dOLFiwINatWxfjxo2LadOmxbPPPtvl/qtWrYqLLroofvazn8Xq1atjzJgx8cEPfjD++te/NvvSACQgZwBoNVkDQFcGFEVRRBPKqyxnnHFG3HnnndX63r17q5C4+uqrY+7cuf/z+D179lRXX8rjZ8yY8apec8eOHTF8+PDYvn17dHR0NPN2Aehn51U5A9D/9fXz6qHOmr4+HgD9zY4WnVebupNs9+7dsXbt2ur24n3fYODAar28ovJqvPDCC/Hiiy/Gscce2+0+u3btqv7B+y8AtD85A0A7ZI2cAeifmirJtm3bVl01GTlyZG17ub558+ZX9T2uueaaOOGEE2qhdKCFCxdWjWDnUl7VAaD9yRkA2iFr5AxA/3RIZ7e85ZZb4sEHH4yHH364ekBmd+bNm1fdMte5bNq06VC+TQD6KTkDQF/IGjkD0D8NbmbnESNGxKBBg2LLli217eX6qFGjXvHY2267rQqUn/zkJ3H66ae/4r5Dhw6tFgBykTMAtEPWyBmABHeSDRkyJCZMmBArV67ct618yGW5PmXKlG6Pu/XWW+Omm26KFStWxMSJEw/uHQPQtuQMAK0mawDolTvJSuVUyTNnzqyCYdKkSbFo0aLYuXNnzJo1q/p6ObvL6NGjq8/hl7761a/G/Pnz44EHHoixY8fu+5z/a17zmmoBgP3JGQBaTdYA0Csl2fTp02Pr1q1VSJThMH78+OpqSueDLzdu3FjNDtPp61//ejWDzIc//OHa91mwYEF88YtfbPblAWhzcgaAVpM1AHRlQFEURfRx5ZTJ5aww5UMvOzo6DvfbAej3nFfrjAdA73JerTMeAP3jvHpIZ7cEAAAAgL5ISQYAAABAekoyAAAAANJTkgEAAACQnpIMAAAAgPSUZAAAAACkpyQDAAAAID0lGQAAAADpKckAAAAASE9JBgAAAEB6SjIAAAAA0lOSAQAAAJCekgwAAACA9JRkAAAAAKSnJAMAAAAgPSUZAAAAAOkpyQAAAABIT0kGAAAAQHpKMgAAAADSU5IBAAAAkJ6SDAAAAID0lGQAAAAApKckAwAAACA9JRkAAAAA6SnJAAAAAEhPSQYAAABAekoyAAAAANJTkgEAAACQnpIMAAAAgPSUZAAAAACkpyQDAAAAID0lGQAAAADpKckAAAAASE9JBgAAAEB6SjIAAAAA0lOSAQAAAJCekgwAAACA9JRkAAAAAKSnJAMAAAAgPSUZAAAAAOkpyQAAAABIT0kGAAAAQHpKMgAAAADSU5IBAAAAkJ6SDAAAAID0lGQAAAAApKckAwAAACA9JRkAAAAA6SnJAAAAAEhPSQYAAABAekoyAAAAANJTkgEAAACQnpIMAAAAgPSUZAAAAACkpyQDAAAAID0lGQAAAADpKckAAAAASE9JBgAAAEB6SjIAAAAA0lOSAQAAAJCekgwAAACA9JRkAAAAAKSnJAMAAAAgPSUZAAAAAOkpyQAAAABIT0kGAAAAQHo9KskWL14cY8eOjWHDhsXkyZNjzZo1r7j/9773vTjllFOq/U877bRYvnx5T98vAAnIGQBaTdYAcNAl2dKlS2POnDmxYMGCWLduXYwbNy6mTZsWzz77bJf7P/7443HRRRfFpZdeGr/+9a/jwgsvrJbf/OY3zb40AAnIGQBaTdYA0JUBRVEU0YTyKssZZ5wRd955Z7W+d+/eGDNmTFx99dUxd+7chv2nT58eO3fujB/96Ef7tr3nPe+J8ePHx5IlS17Va+7YsSOGDx8e27dvj46OjmbeLgD97LwqZwD6v75+Xj3UWdPXxwOgv9nRovPq4GZ23r17d6xduzbmzZu3b9vAgQNj6tSpsXr16i6PKbeXV2n2V16l+cEPftDt6+zatataOpX/6M5BAODgdZ5Pm7xO0nJyBqA99NWcOVRZI2cA+mfONFWSbdu2Lfbs2RMjR46sbS/X169f3+Uxmzdv7nL/cnt3Fi5cGDfeeGPD9vLqDgC95+9//3t1BaavkDMA7aWv5cyhyho5A9A/c6apkuxQKa/q7H+l5rnnnos3vvGNsXHjxj4XsoerMS0DdtOmTW7XNh5dMiZ1xqNReUX7xBNPjGOPPTYykjOvzO9MI2NSZzwaGZM6OSNn/he/M3XGo854NDImhyZnmirJRowYEYMGDYotW7bUtpfro0aN6vKYcnsz+5eGDh1aLQcqA8UPw8vKsTAeLzMejYxJnfFoVH68pC+RM32L35lGxqTOeDQyJn07Zw5V1siZV8/vTJ3xqDMejYxJa3Omqe82ZMiQmDBhQqxcuXLftvIhl+X6lClTujym3L7//qVHH3202/0ByEvOANBqsgaAXvu4ZXnb8MyZM2PixIkxadKkWLRoUTXTy6xZs6qvz5gxI0aPHl19Dr/0mc98Jt73vvfF7bffHuedd148+OCD8atf/SruvvvuZl8agATkDACtJmsA6JWSrJz+eOvWrTF//vzqQZXltMcrVqzY9yDL8nP2+9/uduaZZ8YDDzwQ119/fVx77bXx1re+tZoF5tRTT33Vr1neqrxgwYIub1nOyHjUGY9GxqTOePSvMZEzh5/xaGRM6oxHI2PSv8bjUGdNXx+Pw8GY1BmPOuPRyJgcmvEYUPTFeZkBAAAA4BDqe0/SBAAAAIBDTEkGAAAAQHpKMgAAAADSU5IBAAAAkF6fKckWL14cY8eOjWHDhsXkyZNjzZo1r7j/9773vTjllFOq/U877bRYvnx5tJNmxuOee+6Js88+O4455phqmTp16v8cv/6m2Z+PTuX03AMGDIgLL7ww2k2zY/Lcc8/FVVddFccff3w1A8jJJ5/cVr83zY5HOdX72972tjjyyCNjzJgxMXv27PjPf/4T7eDnP/95nH/++XHCCSdUP//l7Fv/y6pVq+Ld73539bPxlre8Je6///5oN3KmTs40kjV1cqZOzrxMznRNzjSSNXVypk7ONJI1fSBrij7gwQcfLIYMGVLcd999xW9/+9vi8ssvL44++uhiy5YtXe7/i1/8ohg0aFBx6623Fr/73e+K66+/vjjiiCOKJ598smgHzY7HxRdfXCxevLj49a9/XTz11FPFxz/+8WL48OHFX/7ylyLjeHT64x//WIwePbo4++yziw996ENFO2l2THbt2lVMnDixOPfcc4vHHnusGptVq1YVTzzxRJFxPL797W8XQ4cOrf4sx+KRRx4pjj/++GL27NlFO1i+fHlx3XXXFQ899FA5e3Hx8MMPv+L+GzZsKI466qhizpw51Tn1a1/7WnWOXbFiRdEu5EydnGkka+rkTJ2cqZMzjeRMI1lTJ2fq5EwjWdM3sqZPlGSTJk0qrrrqqn3re/bsKU444YRi4cKFXe7/kY98pDjvvPNq2yZPnlx84hOfKNpBs+NxoJdeeql47WtfW3zrW98qso5HOQZnnnlm8Y1vfKOYOXNmWwVKT8bk61//evHmN7+52L17d9GOmh2Pct/3v//9tW3lyfSss84q2s2rCZQvfOELxTvf+c7atunTpxfTpk0r2oWcqZMzjWRNnZypkzPdkzP/JWcayZo6OVMnZxrJmr6RNYf945a7d++OtWvXVrfTdho4cGC1vnr16i6PKbfvv39p2rRp3e7fn/RkPA70wgsvxIsvvhjHHntsZB2PL33pS3HcccfFpZdeGu2mJ2Pywx/+MKZMmVLdnjxy5Mg49dRT4+abb449e/ZExvE488wzq2M6b1/esGFDdav2ueeeGxm18zm1JGfq5EwjWVMnZ+rkzMFr53NqSc40kjV1cqZOzjSSNQevt86rg+Mw27ZtW/WDXf6g769cX79+fZfHbN68ucv9y+39XU/G40DXXHNN9bndA39AsozHY489Fvfee2888cQT0Y56MiblCfOnP/1pfOxjH6tOnM8880x86lOfqv7HY8GCBZFtPC6++OLquPe+973l3bTx0ksvxZVXXhnXXnttZNTdOXXHjh3x73//u3rGQX8mZ+rkTCNZUydn6uTMwZMzuXKmJGvq5EydnGkka/pO1hz2O8noXbfcckv1YMeHH364ethfNs8//3xccskl1YM/R4wYcbjfTp+xd+/e6irU3XffHRMmTIjp06fHddddF0uWLImMygc6llee7rrrrli3bl089NBDsWzZsrjpppsO91uDPi97zpRkTSM5Uydn4OBkzxo500jONJI1rXHY7yQrf+kHDRoUW7ZsqW0v10eNGtXlMeX2ZvbvT3oyHp1uu+22KlB+8pOfxOmnnx7toNnx+MMf/hB/+tOfqlkw9j+hlgYPHhxPP/10nHTSSZHtZ6ScAeaII46ojuv09re/vWrby1t7hwwZEpnG44Ybbqj+x+Oyyy6r1ssZpXbu3BlXXHFFFbblrc2ZdHdO7ejo6PdX90typk7ONJI1dXKmTs4cPDmTK2dKsqZOztTJmUaypu9kzWEftfKHuWyCV65cWTsBlOvlZ467Um7ff//So48+2u3+/UlPxqN06623Vo3xihUrYuLEidEumh2PchrtJ598srotuXO54IIL4pxzzqn+Xk6Lm/Fn5KyzzqpuSe4M19Lvf//7Kmz6e6D0ZDzKZ1wcGBqdgfvf50Lm0s7n1JKcqZMzjWRNnZypkzMHr53PqSU500jW1MmZOjnTSNYcvF47rxZ9ZKrTcurS+++/v5qq84orrqimOt28eXP19UsuuaSYO3dubcrkwYMHF7fddls1PfCCBQvaasrkZsfjlltuqaaK/f73v1/87W9/27c8//zzRcbxOFC7zQTTkzHZuHFjNTvQpz/96eLpp58ufvSjHxXHHXdc8eUvf7nIOB7lOaMcj+985zvVVME//vGPi5NOOqmaaaodlL/75fTp5VKe5u+4447q73/+85+rr5djUY7JgdMlf/7zn6/OqeX06z2ZLrkvkzN1cqaRrKmTM3Vypk7ONJIzjWRNnZypkzONZE3fyJo+UZKVvva1rxUnnnhidWIspz795S9/ue9r73vf+6qTwv6++93vFieffHK1fznN57Jly4p20sx4vPGNb6x+aA5cyl+adtHsz0c7B0pPx+Txxx+vphYvT7zl9Mlf+cpXqmmlM47Hiy++WHzxi1+sQmTYsGHFmDFjik996lPFP//5z6Id/OxnP+vynNA5BuWf5ZgceMz48eOr8St/Pr75zW8W7UbO1MmZRrKmTs7UyZmXyZmuyZlGsqZOztTJmUay5vBnzYDyP71wZxsAAAAA9FuH/ZlkAAAAAHC4KckAAAAASE9JBgAAAEB6SjIAAAAA0lOSAQAAAJCekgwAAACA9JRkAAAAAKSnJAMAAAAgPSUZAAAAAOkpyQAAAABIT0kGAAAAQHpKMgAAAAAiu/8Ho+zDKeRehSMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "models = ['LSTM', 'distilgpt2']\n",
    "rouge1_scores = [lstm_rouge1, final_rouge1]\n",
    "rouge2_scores = [lstm_rouge2, final_rouge2]\n",
    "rougeL_scores = [lstm_rouge_l, final_rouge_l]\n",
    "\n",
    "axes[0].bar(models, rouge1_scores, color=['skyblue', 'lightcoral'])\n",
    "axes[0].set_title('ROUGE-1')\n",
    "axes[0].set_ylabel('Score')\n",
    "for i, v in enumerate(rouge1_scores):\n",
    "    axes[0].text(i, v + 0.001, f'{v:.4f}', ha='center')\n",
    "\n",
    "axes[1].bar(models, rouge2_scores, color=['skyblue', 'lightcoral'])\n",
    "axes[1].set_title('ROUGE-2')\n",
    "axes[1].set_ylabel('Score')\n",
    "for i, v in enumerate(rouge2_scores):\n",
    "    axes[1].text(i, v + 0.001, f'{v:.4f}', ha='center')\n",
    "\n",
    "axes[2].bar(models, rougeL_scores, color=['skyblue', 'lightcoral'])\n",
    "axes[2].set_title('ROUGE-L')\n",
    "axes[2].set_ylabel('Score')\n",
    "for i, v in enumerate(rougeL_scores):\n",
    "    axes[2].text(i, v + 0.001, f'{v:.4f}', ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a47a64f",
   "metadata": {},
   "source": [
    "Выбираем несколько примеров из валидационной выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6045533a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_original' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m sample_indices \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m sample_texts \u001b[38;5;241m=\u001b[39m [val_original[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m sample_indices \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mval_original\u001b[49m)]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_original' is not defined"
     ]
    }
   ],
   "source": [
    "sample_indices = [0, 10, 50, 100, 200]\n",
    "sample_texts = [val_original[i] for i in sample_indices if i < len(val_original)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dce818",
   "metadata": {},
   "source": [
    "Генерация примеров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9ffa3bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m examples \u001b[38;5;241m=\u001b[39m generate_examples(\u001b[43mmodel\u001b[49m, baseline, TOKENIZER, device, sample_texts)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "examples = generate_examples(model, baseline, TOKENIZER, device, sample_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30006c79",
   "metadata": {},
   "source": [
    "### 6. Итоги исследования\n",
    "\n",
    "#### 6.1 Сравнение моделей\n",
    "DistilGPT2 значительно превосходит LSTM по всем метрикам:\n",
    "- ROUGE-L и ROUGE-1: преимущество 83%\n",
    "- ROUGE-2: пятикратное превосходство\n",
    "\n",
    "#### 6.2 Качество генерации\n",
    "Анализ примеров показывает:\n",
    "- LSTM генерирует нерелевантные и бессмысленные продолжения\n",
    "- DistilGPT2 сохраняет контекст и логику исходного текста\n",
    "\n",
    "#### 6.3 Ключевые выводы\n",
    "1. DistilGPT2 демонстрирует абсолютное превосходство над LSTM\n",
    "2. LSTM имеет критические ограничения в понимании контекста\n",
    "\n",
    "#### 6.4 Рекомендации\n",
    "**Основное решение**: внедрение DistilGPT2\n",
    "\n",
    "**Преимущества**:\n",
    "- Высокое качество генерации\n",
    "- Контекстуальная релевантность\n",
    "- Стабильность работы\n",
    "\n",
    "#### 6.5 Заключение\n",
    "DistilGPT2 является оптимальным решением для автодополнения текста в мобильном приложении, обеспечивая значительное улучшение пользовательского опыта при сохранении производительности."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
