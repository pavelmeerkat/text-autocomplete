import torch
from typing import Dict, List, Any
from torch.utils.data import DataLoader
from transformers import AutoTokenizer

from src.eval_lstm import evaluate_rouge
from src.configs import TOKENIZER
from src.data_utils import preprocess_text
from .eval_transformer_pipeline import extract_rouge_score

def compare_models(
        lstm_model, 
        baseline_model, 
        val_loader: DataLoader, 
        val_texts: List[str], 
        device: torch.device
    ) -> Dict[str, Any]:
    
    print("\n=== –°—Ä–∞–≤–Ω–µ–Ω–∏–µ LSTM —Å baseline –º–æ–¥–µ–ª—å—é ===")
    
    print("–û—Ü–µ–Ω–∫–∞ LSTM –º–æ–¥–µ–ª–∏...")
    lstm_rouge_scores = evaluate_rouge(
        model=lstm_model,
        dataloader=val_loader,
        tokenizer=TOKENIZER,
        device=device
    )

    lstm_rouge1 = extract_rouge_score(lstm_rouge_scores['rouge1'])
    lstm_rouge2 = extract_rouge_score(lstm_rouge_scores['rouge2'])
    lstm_rouge_l = extract_rouge_score(lstm_rouge_scores['rougeL'])
    
    print("–û—Ü–µ–Ω–∫–∞ baseline –º–æ–¥–µ–ª–∏...")
    
    baseline_rouge_scores = baseline_model.evaluate_rouge(
        val_texts,
        max_samples=2000,
        max_new_tokens=20
    )
    
    baseline_rouge1 = extract_rouge_score(baseline_rouge_scores['rouge1'])
    baseline_rouge2 = extract_rouge_score(baseline_rouge_scores['rouge2'])
    baseline_rouge_l = extract_rouge_score(baseline_rouge_scores['rougeL'])
    
    print(f"\n–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:")
    print(f"{'–ú–æ–¥–µ–ª—å':<15} {'ROUGE-1':<10} {'ROUGE-2':<10} {'ROUGE-L':<10}")
    print("-" * 50)
    print(f"{'LSTM':<15} {lstm_rouge1:.4f}     {lstm_rouge2:.4f}     {lstm_rouge_l:.4f}")
    print(f"{'Baseline':<15} {baseline_rouge1:.4f}     {baseline_rouge2:.4f}     {baseline_rouge_l:.4f}")
    
    if baseline_rouge_l > lstm_rouge_l:
        best_model = "Baseline"
        print(f"\nBaseline –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (ROUGE-L: {baseline_rouge_l:.4f} vs {lstm_rouge_l:.4f})")
    else:
        best_model = "LSTM"
        print(f"\nLSTM –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (ROUGE-L: {lstm_rouge_l:.4f} vs {baseline_rouge_l:.4f})")
    
    return {
        'lstm_rouge1': lstm_rouge1,
        'lstm_rouge2': lstm_rouge2,
        'lstm_rouge_l': lstm_rouge_l,
        'baseline_rouge1': baseline_rouge1,
        'baseline_rouge2': baseline_rouge2,
        'baseline_rouge_l': baseline_rouge_l,
        'best_model': best_model
    }

def generate_examples(
        lstm_model, 
        baseline_model,
        tokenizer: AutoTokenizer, 
        device: torch.device,
        sample_texts: List[str],
    ) -> List[Dict[str, str]]:
    
    print("\n=== –ü—Ä–∏–º–µ—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ ===")
    
    examples = []
    
    for i, text in enumerate(sample_texts):
        print(f"\n--- –ü—Ä–∏–º–µ—Ä {i+1} ---")
        print(f"–ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç: {text[:100]}...")
        
        try:
            processed_text = preprocess_text(text, tokenizer=None)
            tokens = tokenizer.tokenize(processed_text)
            
            if len(tokens) < 4:
                print("–¢–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                continue
                
            cutoff = max(1, int(len(tokens) * 0.75))
            context_tokens = tokens[:cutoff]
            target_tokens = tokens[cutoff:]
            
            context_text = tokenizer.convert_tokens_to_string(context_tokens)
            target_text = tokenizer.convert_tokens_to_string(target_tokens)
            
            print(f"–ö–æ–Ω—Ç–µ–∫—Å—Ç: {context_text}")
            print(f"–û–∂–∏–¥–∞–µ–º–æ–µ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ: {target_text}")
            
            try:
                input_ids = tokenizer.encode(context_text, return_tensors="pt").to(device)
                lstm_generated = lstm_model.generate(
                    input_ids, tokenizer, 
                    max_new_tokens=len(target_tokens) + 5, 
                    top_k=20
                )
                lstm_continuation = lstm_generated[len(context_text):].strip()
                print(f"LSTM –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ: {lstm_continuation}")
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ LSTM: {e}")
                lstm_continuation = "–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏"
            
            try:
                baseline_generated = baseline_model.generate(
                    context_text, 
                    max_new_tokens=len(target_tokens) + 5
                ).strip()
                
                baseline_continuation = baseline_generated[len(context_text):].strip()
                print(f"Baseline –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ: {baseline_continuation}")
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ Baseline: {e}")
                baseline_continuation = "–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏"
            
            examples.append({
                'original': text,
                'context': context_text,
                'target': target_text,
                'lstm': lstm_continuation,
                'baseline': baseline_continuation
            })
            
        except Exception as e:
            print(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –ø—Ä–∏–º–µ—Ä–∞ {i+1}: {e}")
            print("–ü—Ä–æ–ø—É—Å–∫–∞–µ–º —ç—Ç–æ—Ç –ø—Ä–∏–º–µ—Ä")
            continue
    
    return examples

def create_comparison_report(results: Dict[str, Any], examples: List[Dict[str, str]]) -> str:
    report = []
    report.append("=" * 60)
    report.append("ÔøΩÔøΩ –û–¢–ß–ï–¢ –û –°–†–ê–í–ù–ï–ù–ò–ò –ú–û–î–ï–õ–ï–ô –ê–í–¢–û–î–û–ü–û–õ–ù–ï–ù–ò–Ø –¢–ï–ö–°–¢–ê")
    report.append("=" * 60)
    
    report.append(f"\nüèÜ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {results['best_model']}")
    
    report.append(f"\nÔøΩÔøΩ –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞:")
    report.append(f"{'–ú–æ–¥–µ–ª—å':<15} {'ROUGE-1':<10} {'ROUGE-2':<10} {'ROUGE-L':<10}")
    report.append("-" * 50)
    report.append(f"{'LSTM':<15} {results['lstm_rouge1']:.4f}     {results['lstm_rouge2']:.4f}     {results['lstm_rouge_l']:.4f}")
    report.append(f"{'Baseline':<15} {results['baseline_rouge1']:.4f}     {results['baseline_rouge2']:.4f}     {results['baseline_rouge_l']:.4f}")
    
    report.append(f"\nüìù –ü—Ä–∏–º–µ—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:")
    for i, example in enumerate(examples[:5]):
        report.append(f"\n--- –ü—Ä–∏–º–µ—Ä {i+1} ---")
        report.append(f"–ò—Å—Ö–æ–¥–Ω—ã–π: {example['original'][:50]}...")
        report.append(f"LSTM: {example['lstm']}")
        report.append(f"Baseline: {example['baseline']}")
    
    return "\n".join(report)